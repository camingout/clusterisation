{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data - 11_08_2021_15_17\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "dt = datetime.datetime.now().strftime(\"%d_%m_%Y_%H_%M\")\n",
    "print ('Data -',dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to SQLite DB successful\n"
     ]
    }
   ],
   "source": [
    "# создаем базу данных поменять название базы данных\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import os\n",
    "# try:\n",
    "#     os.remove(\"9-2-2021.sqlite\") \n",
    "# except:pass\n",
    "\n",
    "def create_connection(path):\n",
    "    connection = None\n",
    "    try:\n",
    "        connection = sqlite3.connect(path)\n",
    "        print(\"Connection to SQLite DB successful\")\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "\n",
    "    return connection\n",
    "\n",
    "# connection = create_connection(r\"G:\\Yura\\Python\\Парсер G-Y\\9-2-2021.sqlite\")geotargets.csv 12-32_18-2-2021\n",
    "\n",
    "# connection = create_connection(fr\"C:\\Users\\Lids1\\Desktop\\SEO\\Python\\Парсер G-Y\\{dt}.sqlite\")\n",
    "connection = create_connection(r\"G:\\Yura\\Python\\Парсер G-Y\\11_08_2021_12_37.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully\n",
      "Query executed successfully\n",
      "Query executed successfully\n",
      "Query executed successfully\n",
      "Query executed successfully\n"
     ]
    }
   ],
   "source": [
    "# Создаем таблицы базы данных\n",
    "def execute_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        connection.commit()\n",
    "        print(\"Query executed successfully\")\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "        \n",
    "create_top_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS top (\n",
    "  id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "  keywd TEXT NOT NULL,\n",
    "  url TEXT NOT NULL,\n",
    "  score INTEGER\n",
    ");\n",
    "\"\"\"\n",
    "execute_query(connection, create_top_table)\n",
    "\n",
    "create_keywords_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS keywords (\n",
    "  id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "  fraza TEXT NOT NULL UNIQUE,\n",
    "  score INTEGER\n",
    ");\n",
    "\"\"\"\n",
    "execute_query(connection, create_keywords_table) \n",
    "\n",
    "create_keywords_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS keywords2 (\n",
    "  id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "  fraza TEXT NOT NULL UNIQUE,\n",
    "  score INTEGER\n",
    ");\n",
    "\"\"\"\n",
    "execute_query(connection, create_keywords_table) \n",
    "\n",
    "create_group_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS grup (\n",
    "  id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "  grope TEXT NOT NULL,\n",
    "  keyw TEXT NOT NULL,\n",
    "  score INTEGER\n",
    ");\n",
    "\"\"\"\n",
    "execute_query(connection, create_group_table)\n",
    "\n",
    "create_err_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS errkeys (\n",
    "  id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "  errkey TEXT NOT NULL,\n",
    "  score INTEGER\n",
    ");\n",
    "\"\"\"\n",
    "execute_query(connection, create_err_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete_grup = \"DELETE FROM top\"\n",
    "# execute_query(connection, delete_grup)\n",
    "# delete_grup = \"DELETE FROM keywords\"\n",
    "# execute_query(connection, delete_grup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "66it [00:07,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error 'UNIQUE constraint failed: keywords2.fraza' occurred\n",
      "Скопирована таблица2\n",
      "7 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Наполняем таблицу ключевых фраз\n",
    "import csv\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "\n",
    "def execute_read_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    result = None\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        result = cursor.fetchall()\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "\n",
    "def execute_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        connection.commit()\n",
    "#         print(\"Query executed successfully\")\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "        \n",
    "delete_grup = \"DELETE FROM keywords\"\n",
    "execute_query(connection, delete_grup)\n",
    "\n",
    "def getfile(file):\n",
    "    with open(file, encoding=\"utf8\") as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=\";\")\n",
    "        next(spamreader)\n",
    "        for row in tqdm(spamreader):\n",
    "            clear_output(wait=True)\n",
    "            keyword = row[0].strip().replace('\\ufeff', '')\n",
    "            value = int(row[1].strip().replace('\\ufeff', ''))\n",
    "\n",
    "            create_keyword = f\"\"\"\n",
    "            INSERT OR IGNORE INTO\n",
    "              keywords (fraza, score)\n",
    "            VALUES\n",
    "              ('{keyword}', '{value}');\n",
    "            \"\"\"\n",
    "\n",
    "            execute_query(connection, create_keyword)  \n",
    "            \n",
    "\n",
    "    csvfile.close()\n",
    "\n",
    "t0 = time()  \n",
    "file = 'keys-for-cluster_ua.csv'\n",
    "# file = 'keys-for-top-city.csv'\n",
    "getfile(file)\n",
    "#Копируем таблицу в keywords2\n",
    "copy_table = \"INSERT INTO keywords2 SELECT * FROM keywords\"\n",
    "keywords = execute_read_query(connection, copy_table)\n",
    "print('Скопирована таблица2')\n",
    "print(int(time() - t0), 'sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def execute_read_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    result = None\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        result = cursor.fetchall()\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "        \n",
    "select_users = \"SELECT * from keywords\"\n",
    "keywords = execute_read_query(connection, select_users)\n",
    "len(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delete_grup = \"DELETE FROM top\"\n",
    "execute_query(connection, delete_grup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uule = 'w+CAIQICIbT2Rlc2EsT2Rlc3NhIE9ibGFzdCxVa3JhaW5l'\n",
    "hl = 'ru'\n",
    "country = 'SE'  \n",
    "num = '30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w+CAIQICINVW5pdGVkIFN0YXRlcw\n"
     ]
    }
   ],
   "source": [
    "# Данные Гео для парсинга\n",
    "import uule_grabber\n",
    "\n",
    "hl = 'en' #hl=sv          Swedish https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes\n",
    "country = 'us' #se \tSweden  \n",
    "num = '10' # Количество результатов поиска\n",
    "zone = 'com' #'com.ua'\n",
    "region = 'United States'  #'Kyiv,Kyiv city,Ukraine', 'UA'   New York,New York,United States   Moscow,Moscow,Russia\n",
    "uule = uule_grabber.uule(region)\n",
    "print(uule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done - 66\n",
      "buying web server cloud 1\n",
      "parsing\n",
      "Обработка\n",
      "14\n",
      "Також питають:\n",
      "https://www.ionos.com/cloud/cloud-servers\n",
      "https://en.wikipedia.org/wiki/Cloud_storage\n",
      "https://www.i2k2.com/blog/comparison-aws-traditional-web-hosting-services/\n",
      "https://www.techradar.com/web-hosting/consider-these-9-things-when-buying-a-web-hosting-service\n",
      "Органічний пошук\n",
      "10\n",
      "https://www.pcmag.com/picks/the-best-cloud-web-hosting-services\n",
      "https://www.techradar.com/news/best-cloud-hosting-providers\n",
      "https://cloud.google.com/solutions/web-hosting\n",
      "https://www.quicksprout.com/best-cloud-web-hosting/\n",
      "https://www.websitebuilderexpert.com/web-hosting/cloud-hosts/\n",
      "https://www.resellerclub.com/cloud-hosting\n",
      "https://aws.amazon.com/websites/\n",
      "https://www.cnet.com/tech/services-and-software/best-web-hosting/\n",
      "https://www.hostinger.com/cloud-hosting\n",
      "https://www.tomsguide.com/buying-guide/best-cloud-hosting-services\n",
      "Не собрано 0 Done\n"
     ]
    }
   ],
   "source": [
    "# Work 2 по кількості People Asc\n",
    "#Общий скрипт для сбора ТОП модуль для прокси \n",
    "# from selenium.webdriver.support.wait import WebDriverWait\n",
    "import json\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# import datetime\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "import csv\n",
    "import secrets\n",
    "# import zipfile\n",
    "import xlsxwriter\n",
    "\n",
    "from seleniumwire import webdriver\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "# from fake_useragent import UserAgent\n",
    "# from proxy_auth_data import login, password\n",
    "\n",
    "# options\n",
    "# options = webdriver.ChromeOptions()\n",
    "\n",
    "# change useragent\n",
    "# useragent = UserAgent()\n",
    "useragent = 'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36'\n",
    "\n",
    "fil = str('google.'+country+ dt + '.csv')\n",
    "# filename = fil\n",
    "inindex =[]\n",
    "zeroresult = []\n",
    "proxies = []\n",
    "# noindex = []\n",
    "def execute_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "        \n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        connection.commit()\n",
    "#         print(\"Query executed successfully\")\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "        \n",
    "def execute_read_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    result = None\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        result = cursor.fetchall()\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "\n",
    "# read proxy list\n",
    "fileproxy = 'Proxy_HTTP1.txt'\n",
    "def listOfproxy(fileproxy):\n",
    "    global PROXY_USER\n",
    "    global PROXY_PASS\n",
    "    global PROXY_PORT\n",
    "    with open(fileproxy, 'r', encoding=\"utf-8\") as f:\n",
    "        proxies1 = list(filter(lambda x: len(x.strip()) > 0, f))\n",
    "    proxies2 = list(map(lambda x: x.replace('\\n', '').replace(' ', ''), proxies1))\n",
    "    pro = {}\n",
    "    for g in proxies2:\n",
    "        k = g.split(':')[0]\n",
    "        v = g.split(':')[1]\n",
    "        pro[k] = v\n",
    "    PROXY_HTTP = pro.pop('ProxyType')\n",
    "    PROXY_USER = pro.pop('Login')  # username\n",
    "    PROXY_PASS = pro.pop('Password') # password tipfoto\n",
    "    proxies = list(map(lambda x: x, pro.keys()))\n",
    "    PROXY_HOST = secrets.choice(proxies)\n",
    "    PROXY_PORT = int(list(map(lambda x: x, pro.values()))[0])\n",
    "    # print(PROXY_HOST)\n",
    "    return proxies\n",
    "\n",
    "# create your useragent_random\n",
    "def useragent_r():\n",
    "    print('Start')\n",
    "    useragent_random = useragent.random\n",
    "#     if (useragent_random is None): \n",
    "    if ('Ubuntu' in useragent_random or 'compatible' in useragent_random or 'U;' in useragent_random or 'x64' in useragent_random): \n",
    "#         print('- Ubuntu', useragent_random)\n",
    "        useragent_random2 = useragent_r()\n",
    "#         print('- New')\n",
    "        return useragent_random2\n",
    "#     elif (useragent_random is None):\n",
    "#         print('- None', useragent_random)\n",
    "#         useragent_random = useragent.random\n",
    "    else:\n",
    "#         print('Non_Ubuntu')\n",
    "        return useragent_random\n",
    "\n",
    "# сохраняем массив собраных урлов        \n",
    "def savesqllist(inindex):\n",
    "#     print(inindex)\n",
    "    for f in inindex:\n",
    "        query = f[0]\n",
    "        url_filter = f[1]\n",
    "#         score = f[2]\n",
    "        score = inindex.index(f)+1\n",
    "        create_top = f\"\"\"\n",
    "        INSERT INTO\n",
    "          top (keywd, url, score)\n",
    "        VALUES\n",
    "          ('{query}', '{url_filter}', '{score}');\n",
    "        \"\"\"\n",
    "\n",
    "        execute_query(connection, create_top) \n",
    "#     clear_output(wait=True)\n",
    "#         print('sql - Done')\n",
    "\n",
    "# сохраняем фразу если ошибка\n",
    "def saveerr(query, score):\n",
    "        create_err = f\"\"\"\n",
    "        INSERT OR IGNORE INTO\n",
    "          errkeys (errkey, score)\n",
    "        VALUES\n",
    "          ('{query}', '{score}');\n",
    "        \"\"\"\n",
    "\n",
    "        execute_query(connection, create_err)         \n",
    "\n",
    "\n",
    "#get_chromedriver Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36\n",
    "def get_chromedriver(use_proxy=False, user_agent=None):\n",
    "    global PROXY_HOST\n",
    "    global proxies\n",
    "#     useragent_random = useragent_r()\n",
    "#     print(useragent_random)\n",
    "    useragent_random = useragent\n",
    "    path = os.path.dirname(os.path.abspath(r\"C:\\Users\\Lids1.SERVER\\Desktop\\Python\\selenium\\chrome1\\chromedriver\"))\n",
    "#     path = os.path.dirname(os.path.abspath(r\"C:\\Users\\Admin\\Documents\\Python\\selenium\\chrome\\chromedriver\"))\n",
    "#     path = os.path.dirname(os.path.abspath(r\"C:\\Users\\Lids1\\Desktop\\SEO\\Python\\selenium\\chrome\\chromedriver\"))\n",
    "    if len(proxies) < 3:\n",
    "        proxies = listOfproxy(fileproxy)\n",
    "#         proxies = list(map(lambda x: x, pro.keys()))\n",
    "    PROXY_HOST = secrets.choice(proxies)\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.headless = True\n",
    "    # disable webdriver mode\n",
    "\n",
    "    # for ChromeDriver version 79.0.3945.16 or over\n",
    "    chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "#     chrome_options.add_argument(f'user-agent={useragent}')\n",
    "    #chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    #chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    chrome_options.add_argument(f\"user-agent={useragent_random}\")\n",
    "    \n",
    "    proxy_options = {\n",
    "        'proxy': {\n",
    "            'https': f'https://{PROXY_USER}:{PROXY_PASS}@{PROXY_HOST}:{PROXY_PORT}'\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    driver = webdriver.Chrome(\n",
    "        os.path.join(path, 'chromedriver'),\n",
    "        seleniumwire_options=proxy_options,\n",
    "        options=chrome_options)\n",
    "#     print (PROXY_HOST)\n",
    "    return driver\n",
    "\n",
    "def get_driver(query, score):\n",
    "    \n",
    "    driver = get_chromedriver(use_proxy=True)\n",
    "    try:\n",
    "        queryl = re.sub('\\s','%20',query)\n",
    "        takeurl = f'https://www.google.{zone}/search?q={queryl}&pws=0&uule={uule}&hl={hl}&gl={country}&ip=0.0.0.0&source_ip=0.0.0.0&num={num}'\n",
    "#         takeurl = f'https://www.google.com.ua/webhp?hl={hl}&uule={uule}&gl={country}&ip=0.0.0.0&source_ip=0.0.0.0&num={num}'\n",
    "        driver.get(takeurl)\n",
    "        time.sleep(1)\n",
    "        # Проверяем если капча\n",
    "        result_search = driver.find_elements_by_xpath(\"//form[@id='captcha-form']\")\n",
    "        if (result_search):\n",
    "            print ('Reboot proxy')\n",
    "            proxies.remove(PROXY_HOST)\n",
    "            time.sleep(1)\n",
    "            driver.close()\n",
    "            driver.quit()\n",
    "#             try: os.system(\"taskkill /im chromedriver.exe\")\n",
    "#             except: pass\n",
    "            get_driver(query, score)\n",
    "        else:\n",
    "            # Проверяем если нет результатов в выдаче\n",
    "            try:\n",
    "                result_num = driver.find_elements_by_xpath(\"//div[@id='result-stats']\")[0]\n",
    "                if result_num.text.split(' ')[2] == '0': return\n",
    "            except:pass\n",
    "            try:\n",
    "                result_num = driver.find_element_by_xpath(\"//div[@class='card-section']\")\n",
    "                if len(result_num.text.split(' ')[:2]) == 2: return\n",
    "            except:pass\n",
    "            print('parsing')\n",
    "            try:\n",
    "                result_stats = driver.find_elements_by_xpath(\"//div[@class='yuRUbf']/a\")\n",
    "                result_asc = driver.find_element_by_xpath(\"//div[@class='Wt5Tfe']\")\n",
    "                result_asc2 = result_asc.find_elements_by_xpath(\"//div[@jsname='Cpkphb']\")\n",
    "                result_asc1 = result_asc.find_elements_by_xpath(\"//div[@class='yuRUbf']/a\")\n",
    "            except:\n",
    "                print('ошибка сбора данных')\n",
    "                pass\n",
    "#             result_stats = driver.find_elements_by_xpath(\"//div[@class='r']/a\")\n",
    "            print('Обработка')\n",
    "            inindex.clear()\n",
    "            zeroresult.clear()\n",
    "            print(len(result_stats))\n",
    "            if (len(result_stats) == 0):        \n",
    "                print ('Пусто')\n",
    "                time.sleep(1)\n",
    "                saveerr(query, score)\n",
    "                return\n",
    "\n",
    "            else:\n",
    "                asc_urls = []\n",
    "                f = 0\n",
    "                try:\n",
    "                    print('Також питають: ', len(result_asc2))\n",
    "                    for links in result_asc1[1:]:\n",
    "                        url_filter = links.get_attribute('href')\n",
    "                        if 'translate' in url_filter: continue\n",
    "                        if url_filter not in asc_urls:\n",
    "                            f = f +1\n",
    "                            asc_urls.append(url_filter)\n",
    "                            print(url_filter)\n",
    "                            if f == len(result_asc2): break\n",
    "                except:\n",
    "                    print('ошибка asc')\n",
    "                    pass\n",
    "                all_urls = []\n",
    "                print('Органічний пошук')\n",
    "                for links in result_stats:\n",
    "                    url_filter = links.get_attribute('href')\n",
    "                #     if 'translate' in url_filter or 'google' in url_filter: continue\n",
    "                    if 'translate' in url_filter: continue\n",
    "                    all_urls.append(url_filter)\n",
    "                    if url_filter in asc_urls:\n",
    "                        all_urls.remove(url_filter)\n",
    "                        asc_urls.remove(url_filter)\n",
    "                print(len(all_urls))\n",
    "                for links in all_urls:\n",
    "                    print(links)\n",
    "                    inindex.append([query, links, score])\n",
    "                savesqllist(inindex)\n",
    "                # удаляем из таблицы ключ\n",
    "                delete_keyword = f\"DELETE FROM keywords WHERE fraza = '{query}'\"\n",
    "                execute_query(connection, delete_keyword)\n",
    "\n",
    "            time.sleep(1)\n",
    "            driver.close()\n",
    "            driver.quit()\n",
    "            return\n",
    "    except:\n",
    "        driver.close()\n",
    "        driver.quit()\n",
    "        time.sleep(10)\n",
    "        print('Перезапуск get_driver(query, score)')\n",
    "        get_driver(query, score)\n",
    "        pass\n",
    "def read_queries_list_from_file(filename):\n",
    "    f = open( filename, mode = 'r', encoding = 'utf-8' )    \n",
    "    return [x.strip() for x in f]\n",
    "\n",
    "def getkeys(keywords):\n",
    "    delete_grup = \"DELETE FROM errkeys\"\n",
    "    execute_query(connection, delete_grup)\n",
    "    i = 0\n",
    "    for row in keywords:\n",
    "        clear_output(wait=True)\n",
    "        i += 1\n",
    "        print('Done -', i)\n",
    "        query = row[1]\n",
    "        score = row[2]\n",
    "        print(query, score)\n",
    "        get_driver(query, score)\n",
    "        \n",
    "        \n",
    "def main():\n",
    "    # получаем прокси\n",
    "    proxies = listOfproxy(fileproxy)\n",
    "\n",
    "    select_keywords = \"SELECT * from keywords\"\n",
    "    keywords = execute_read_query(connection, select_keywords)\n",
    "    getkeys(keywords)\n",
    "    # пороверка на ошибки сбора\n",
    "    select_keywords = \"SELECT * from errkeys\"\n",
    "    keywords = execute_read_query(connection, select_keywords)\n",
    "    if keywords:\n",
    "        print(\"Досбор\")\n",
    "        getkeys(keywords)\n",
    "    select_keywords = \"SELECT * from errkeys\"\n",
    "    keywords = execute_read_query(connection, select_keywords)\n",
    "\n",
    "    print('Не собрано', len(keywords), 'Done')\n",
    "\n",
    "    # os.startfile(fil)        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем ТОП в файл\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "def execute_read_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    result = None\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        result = cursor.fetchall()\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "\n",
    "dt = datetime.datetime.now().strftime(\"%d_%m_%Y_%H_%M\")\n",
    "fil = dt+\"_top.csv\"\n",
    "\n",
    "addCluster = []\n",
    "cluster = 'Grope@Keys'\n",
    "addCluster.append(cluster)\n",
    "\n",
    "select_users = \"SELECT * from top\"\n",
    "keywords = execute_read_query(connection, select_users)\n",
    "\n",
    "\n",
    "for result in keywords:\n",
    "    groupTop = result[1]\n",
    "    keywordTop = result[2]\n",
    "    cluster = f'{groupTop}@{keywordTop}'\n",
    "    addCluster.append(cluster)\n",
    "    \n",
    "def savefile(inindex):\n",
    "    with open(fil, 'a', encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f, lineterminator='\\n')\n",
    "        #wr = csv.writer(f, quoting=csv.QUOTE_ALL)\n",
    "        #wr.writerow(inindex)\n",
    "        for item in inindex:\n",
    "            w.writerow([item])\n",
    "#     time.sleep(2)\n",
    "    f.close()\n",
    "savefile(addCluster)\n",
    "import pandas\n",
    "\n",
    "file_read = pandas.read_csv(fil, delimiter='@')\n",
    "file_read.to_excel(dt+\"_top.xlsx\", index=None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Удаление записей из таблицы keywords если остановился сбор\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "with open('donekey.txt', 'r', encoding=\"utf-8\") as f:\n",
    "    donekey = list(filter(lambda x: len(x.strip()) > 0, f))\n",
    "donekey = list(map(lambda x: x.replace('\\n', ''), donekey))\n",
    "\n",
    "def execute_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        connection.commit()\n",
    "#         print(\"Query executed successfully\")\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "\n",
    "for f in tqdm(donekey):\n",
    "    clear_output(wait=True)\n",
    "    delete_keyword = f\"DELETE FROM keywords WHERE fraza = '{f}'\"\n",
    "    execute_query(connection, delete_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 66/66 [00:08<00:00,  7.72it/s]\n"
     ]
    }
   ],
   "source": [
    "#Кластеризатор из базы данных + value Midle\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def execute_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "        \n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        connection.commit()\n",
    "#         print(\"Query executed successfully\")\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "        \n",
    "def execute_read_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    result = None\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        result = cursor.fetchall()\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "        \n",
    "delete_grup = \"DELETE FROM grup\"\n",
    "execute_query(connection, delete_grup)\n",
    "\n",
    "clasterKeys = []\n",
    "clasterKey = []\n",
    "typeCl = 'Midle'\n",
    "\n",
    "select_keywords = \"SELECT * from keywords2\"\n",
    "keywords = execute_read_query(connection, select_keywords)\n",
    "\n",
    "top_urls = \"SELECT * from top\"\n",
    "top_urls = execute_read_query(connection, top_urls)\n",
    "\n",
    "for i in tqdm(keywords):\n",
    "#     clear_output(wait=True)\n",
    "    keyword = i[1]\n",
    "    if keyword in clasterKeys: continue\n",
    "\n",
    "    clasterKeyM = []\n",
    "    clasterKeyM = list(map(lambda x: x[2], list(filter(lambda x: x[1] == keyword, top_urls))))\n",
    "\n",
    "\n",
    "    for h in keywords:\n",
    "#         clear_output(wait=True)\n",
    "        keynext = h[1]\n",
    "        value = h[2]\n",
    "        if keynext in clasterKeys: continue\n",
    "\n",
    "        clasterKeyD = []\n",
    "        clasterKeyD = list(map(lambda x: x[2], list(filter(lambda x: x[1] == keynext, top_urls))))\n",
    "\n",
    "        result=list(set(clasterKeyM) & set(clasterKeyD)) \n",
    "\n",
    "        if len(result) > 2:\n",
    "\n",
    "            clasterKeys.append(keynext)\n",
    "\n",
    "\n",
    "            create_groop = f\"\"\"\n",
    "            INSERT INTO\n",
    "              `grup` (`grope`, `keyw`, `score`)\n",
    "            VALUES\n",
    "              ('{keyword}', '{keynext}', '{value}');\n",
    "            \"\"\"\n",
    "\n",
    "            execute_query(connection, create_groop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 66/66 [00:06<00:00, 10.39it/s]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 66/66 [00:08<00:00,  7.78it/s]\n"
     ]
    }
   ],
   "source": [
    "#Кластеризатор из базы данных + value Midle+Soft\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def execute_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "        \n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        connection.commit()\n",
    "#         print(\"Query executed successfully\")\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "        \n",
    "def execute_read_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    result = None\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        result = cursor.fetchall()\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "        \n",
    "delete_grup = \"DELETE FROM grup\"\n",
    "execute_query(connection, delete_grup)\n",
    "\n",
    "clasterKeys = []\n",
    "clasterKey = []\n",
    "typeCl = 'Midle_Soft'\n",
    "\n",
    "\n",
    "select_keywords = \"SELECT * from keywords2\"\n",
    "keywords = execute_read_query(connection, select_keywords)\n",
    "\n",
    "top_urls = \"SELECT * from top\"\n",
    "top_urls = execute_read_query(connection, top_urls)\n",
    "\n",
    "for i in tqdm(keywords):\n",
    "    clasterKeysGroup = []\n",
    "#     clear_output(wait=True)\n",
    "    keyword = i[1]\n",
    "    if keyword in clasterKeys: continue\n",
    "    #Урли материнської групи\n",
    "    clasterKeyM = []\n",
    "    clasterKeyM = list(map(lambda x: x[2], list(filter(lambda x: x[1] == keyword, top_urls))))\n",
    "    clasterKeysGroup.append(keyword)\n",
    "\n",
    "    for h in keywords:\n",
    "#         clear_output(wait=True)\n",
    "        keynext = h[1]\n",
    "        value = h[2]\n",
    "        if keynext in clasterKeys: continue\n",
    "        #Урли дочірньої групи\n",
    "        clasterKeyD = []\n",
    "        clasterKeyD = list(map(lambda x: x[2], list(filter(lambda x: x[1] == keynext, top_urls))))\n",
    "\n",
    "        result=list(set(clasterKeyM) & set(clasterKeyD)) \n",
    "\n",
    "        if len(result) > 2:\n",
    "            clasterKeys.append(keynext)\n",
    "            clasterKeysGroup.append(keynext)\n",
    "\n",
    "            create_groop = f\"\"\"\n",
    "            INSERT INTO\n",
    "              `grup` (`grope`, `keyw`, `score`)\n",
    "            VALUES\n",
    "              ('{keyword}', '{keynext}', '{value}');\n",
    "            \"\"\"\n",
    "\n",
    "            execute_query(connection, create_groop)\n",
    "        \n",
    "            for j in keywords:\n",
    "                lastkeyword = clasterKeysGroup[-1]\n",
    "                clasterKeyC = []\n",
    "                clasterKeyC = list(map(lambda x: x[2], list(filter(lambda x: x[1] == lastkeyword, top_urls))))\n",
    "        #         clear_output(wait=True)\n",
    "                keynext = j[1]\n",
    "                value = j[2]\n",
    "                if keynext in clasterKeys: continue\n",
    "\n",
    "                clasterKeyE = []\n",
    "                clasterKeyE = list(map(lambda x: x[2], list(filter(lambda x: x[1] == keynext, top_urls))))\n",
    "\n",
    "                result=list(set(clasterKeyC) & set(clasterKeyE)) \n",
    "\n",
    "                if len(result) > 2:\n",
    "\n",
    "                    clasterKeys.append(keynext)\n",
    "                    clasterKeysGroup.append(keynext)\n",
    "\n",
    "\n",
    "                    create_groop = f\"\"\"\n",
    "                    INSERT INTO\n",
    "                      `grup` (`grope`, `keyw`, `score`)\n",
    "                    VALUES\n",
    "                      ('{keyword}', '{keynext}', '{value}');\n",
    "                    \"\"\"\n",
    "\n",
    "                    execute_query(connection, create_groop)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Сохраняем кластеры\n",
    "import xlsxwriter\n",
    "import datetime\n",
    "\n",
    "def execute_read_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    result = None\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        result = cursor.fetchall()\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "\n",
    "dt = datetime.datetime.now().strftime(\"%d_%m_%Y_%H_%M\")\n",
    " \n",
    "addCluster = []\n",
    "cluster = ('Grope', 'Keys', 'Value')\n",
    "addCluster.append(cluster)\n",
    "\n",
    "select_users = \"SELECT * from grup\"\n",
    "keywords = execute_read_query(connection, select_users)\n",
    "\n",
    "\n",
    "for result in keywords:\n",
    "    groupTop = result[1]\n",
    "    keywordTop = result[2]\n",
    "    valueTop = result[3]\n",
    "    cluster = (groupTop, keywordTop, valueTop)\n",
    "    addCluster.append(cluster)\n",
    "    \n",
    "with xlsxwriter.Workbook(f'{dt}_clusters_{typeCl}.xlsx') as workbook:\n",
    "    worksheet = workbook.add_worksheet()\n",
    "    for row_num, data in enumerate(addCluster):\n",
    "        worksheet.write_row(row_num, 0, data)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Для анализа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_read_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    result = None\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        result = cursor.fetchall()\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keynext = 'брендовый спортивный костюм мужской'\n",
    "select_urls = f\"\"\"\n",
    "        SELECT\n",
    "          top.keywd,\n",
    "          top.url\n",
    "        FROM\n",
    "          top\n",
    "        WHERE\n",
    "          top.keywd = '{keynext}'\n",
    "        \"\"\"\n",
    "top_urls = execute_read_query(connection, select_urls)\n",
    "top_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "878"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_users = \"SELECT * from top\"\n",
    "keywords = execute_read_query(connection, select_users)\n",
    "len(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5498"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_users = \"SELECT * from keywords2\"\n",
    "keywords = execute_read_query(connection, select_users)\n",
    "len(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_users = \"SELECT * from grup\"\n",
    "keywords = execute_read_query(connection, select_users)\n",
    "len(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(57, 'купить профнастил для забора 2 метра', 590),\n",
       " (206, 'профнастил пс 8', 170),\n",
       " (280, 'профлист оцинкованный', 110),\n",
       " (798, 'купить металлопрофиль под дерево', 30),\n",
       " (898, 'профнастил в херсоне', 30),\n",
       " (1123, 'металлопрофиль забор цена', 20),\n",
       " (1192, 'профнастил 3м', 20),\n",
       " (1215, 'профнастил алюминиевый', 20),\n",
       " (1293, 'цена металопрофіль', 20),\n",
       " (1318, 'купить профнастил для забора одесса', 20),\n",
       " (1374, 'профнастил крыши цена', 20),\n",
       " (1630, 'профнастил киев выдубичи', 20),\n",
       " (1668, 'с44', 10),\n",
       " (1871, 'профлист зеленый', 10),\n",
       " (2106, 'стоимость метра забора из профлиста', 10),\n",
       " (2695, 'металлопрофиль монтаж', 10),\n",
       " (2866, 'металлопрофиль старый оскол', 10),\n",
       " (2891, 'металлопрофиль труба купить', 10),\n",
       " (2948, 'металлопрофиль это', 10),\n",
       " (3293, 'купить профнастил боярка', 10),\n",
       " (3500, 'ворота профнастил ковка', 10),\n",
       " (3575, 'профнастил южно сахалинск сахалинская область', 10),\n",
       " (3949, 'профнастил под камень купить украина', 10),\n",
       " (4152, 'польский профнастил', 10),\n",
       " (4305, 'ворота распашные профнастил', 10),\n",
       " (4421, 'профнастил с двухсторонним полимерным покрытием', 10),\n",
       " (4469, 'профнастил из оцинкованной стали', 10),\n",
       " (4556, 'профнастил в славянске', 10),\n",
       " (4755, 'металлобаза металлопрокат и профнастил', 10),\n",
       " (4809, 'профнастил нс 44 производитель', 10),\n",
       " (4976, 'профнастил нс 35 монтаж', 10),\n",
       " (5197, 'купити профнастил біла церква', 10),\n",
       " (5237, 'профнастил волна 10', 10),\n",
       " (5356, 'профнастил н114 600', 10)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_users = \"SELECT * from keywords\"\n",
    "keywords = execute_read_query(connection, select_users)\n",
    "len(keywords)\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "select_users = \"SELECT * from errkeys\"\n",
    "keywords = execute_read_query(connection, select_users)\n",
    "# len(keywords)\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_grup = \"DELETE FROM keywords\"\n",
    "execute_query(connection, delete_grup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_users = \"SELECT * from geotargets\"\n",
    "keywords = execute_read_query(connection_geo, select_users)\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSERT INTO new_db.table_name SELECT * FROM old_db.table_name;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_table = \"INSERT INTO keywords2 SELECT * FROM keywords\"\n",
    "keywords = execute_read_query(connection, copy_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully\n"
     ]
    }
   ],
   "source": [
    "def execute_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        connection.commit()\n",
    "        print(\"Query executed successfully\")\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "        \n",
    "\n",
    "create_keywords_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS keywords2 (\n",
    "  id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "  fraza TEXT NOT NULL UNIQUE,\n",
    "  score INTEGER\n",
    ");\n",
    "\"\"\"\n",
    "execute_query(connection, create_keywords_table) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Общий скрипт для сбора ТОП модуль для прокси\n",
    "# from selenium.webdriver.support.wait import WebDriverWait\n",
    "import json\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# import datetime\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "import csv\n",
    "import secrets\n",
    "# import zipfile\n",
    "import xlsxwriter\n",
    "\n",
    "from seleniumwire import webdriver\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "# from fake_useragent import UserAgent\n",
    "# from proxy_auth_data import login, password\n",
    "\n",
    "# options\n",
    "# options = webdriver.ChromeOptions()\n",
    "\n",
    "# change useragent\n",
    "# useragent = UserAgent()\n",
    "useragent = 'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36'\n",
    "\n",
    "\n",
    "\n",
    "fil = str('google.'+country+ dt + '.csv')\n",
    "# filename = fil\n",
    "inindex =[]\n",
    "zeroresult = []\n",
    "proxies = []\n",
    "# noindex = []\n",
    "def execute_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "        \n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        connection.commit()\n",
    "#         print(\"Query executed successfully\")\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "        \n",
    "def execute_read_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    result = None\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        result = cursor.fetchall()\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "\n",
    "# read proxy list\n",
    "fileproxy = 'Proxy_HTTP1.txt'\n",
    "def listOfproxy(fileproxy):\n",
    "    global PROXY_USER\n",
    "    global PROXY_PASS\n",
    "    global PROXY_PORT\n",
    "    with open(fileproxy, 'r', encoding=\"utf-8\") as f:\n",
    "        proxies1 = list(filter(lambda x: len(x.strip()) > 0, f))\n",
    "    proxies2 = list(map(lambda x: x.replace('\\n', '').replace(' ', ''), proxies1))\n",
    "    pro = {}\n",
    "    for g in proxies2:\n",
    "        k = g.split(':')[0]\n",
    "        v = g.split(':')[1]\n",
    "        pro[k] = v\n",
    "    PROXY_HTTP = pro.pop('ProxyType')\n",
    "    PROXY_USER = pro.pop('Login')  # username\n",
    "    PROXY_PASS = pro.pop('Password') # password tipfoto\n",
    "    proxies = list(map(lambda x: x, pro.keys()))\n",
    "    PROXY_HOST = secrets.choice(proxies)\n",
    "    PROXY_PORT = int(list(map(lambda x: x, pro.values()))[0])\n",
    "    # print(PROXY_HOST)\n",
    "    return proxies\n",
    "\n",
    "# create your useragent_random\n",
    "def useragent_r():\n",
    "    print('Start')\n",
    "    useragent_random = useragent.random\n",
    "#     if (useragent_random is None): \n",
    "    if ('Ubuntu' in useragent_random or 'compatible' in useragent_random or 'U;' in useragent_random or 'x64' in useragent_random): \n",
    "#         print('- Ubuntu', useragent_random)\n",
    "        useragent_random2 = useragent_r()\n",
    "#         print('- New')\n",
    "        return useragent_random2\n",
    "#     elif (useragent_random is None):\n",
    "#         print('- None', useragent_random)\n",
    "#         useragent_random = useragent.random\n",
    "    else:\n",
    "#         print('Non_Ubuntu')\n",
    "        return useragent_random\n",
    "\n",
    "# сохраняем массив собраных урлов        \n",
    "def savesqllist(inindex):\n",
    "#     print(inindex)\n",
    "    for f in inindex:\n",
    "        query = f[0]\n",
    "        url_filter = f[1]\n",
    "#         score = f[2]\n",
    "        score = inindex.index(f)+1\n",
    "        create_top = f\"\"\"\n",
    "        INSERT INTO\n",
    "          top (keywd, url, score)\n",
    "        VALUES\n",
    "          ('{query}', '{url_filter}', '{score}');\n",
    "        \"\"\"\n",
    "\n",
    "        execute_query(connection, create_top) \n",
    "#     clear_output(wait=True)\n",
    "#         print('sql - Done')\n",
    "\n",
    "# сохраняем фразу если ошибка\n",
    "def saveerr(query, score):\n",
    "        create_err = f\"\"\"\n",
    "        INSERT OR IGNORE INTO\n",
    "          errkeys (errkey, score)\n",
    "        VALUES\n",
    "          ('{query}', '{score}');\n",
    "        \"\"\"\n",
    "\n",
    "        execute_query(connection, create_err)         \n",
    "#parse_result_-h3.People also ask\n",
    "def parse_result(result_asc1, result_asc2, result_stats, query, score):\n",
    "# def parse_result(driver, query, score):\n",
    "    inindex.clear()\n",
    "    zeroresult.clear()\n",
    "    print(len(result_stats))\n",
    "    if (len(result_stats) == 0):        \n",
    "        print ('Пусто')\n",
    "        time.sleep(1)\n",
    "        saveerr(query, score)\n",
    "#         zeroresult.append(query)\n",
    "#         filename = ('zero_'+fil)\n",
    "#         savefilevital(zeroresult)\n",
    "        return\n",
    "\n",
    "    else:\n",
    "        asc_urls = []\n",
    "        if result_asc2:\n",
    "            try:\n",
    "                print('обрабатываем asc')            \n",
    "                f = 0\n",
    "                for links in result_asc1:\n",
    "                    url_filter = links.get_attribute('href')\n",
    "                    if 'translate' in url_filter: continue\n",
    "                    if url_filter not in asc_urls:\n",
    "                        f = f +1\n",
    "                        asc_urls.append(url_filter)\n",
    "                        print(url_filter)\n",
    "                        if f == len(result_asc2): break\n",
    "            except:\n",
    "                print('Не собрались данные asc')\n",
    "                pass\n",
    "        all_urls = []\n",
    "        for links in result_stats:\n",
    "            url_filter = links.get_attribute('href')\n",
    "        #     if 'translate' in url_filter or 'google' in url_filter: continue\n",
    "            if 'translate' in url_filter: continue\n",
    "            all_urls.append(url_filter)\n",
    "            if url_filter in asc_urls:\n",
    "                all_urls.remove(url_filter)\n",
    "                asc_urls.remove(url_filter)\n",
    "        for links in all_urls:\n",
    "            inindex.append([query, links, score])\n",
    "# #parse_result_-h3.People also ask\n",
    "# def parse_result(result_asc1, result_asc2, result_stats, query, score):\n",
    "# # def parse_result(driver, query, score):\n",
    "#     print('Парсинг результатов')\n",
    "#     try:\n",
    "#         result_stats = driver.find_elements_by_xpath(\"//div[@class='yuRUbf']/a\")\n",
    "#         try:\n",
    "#             result_asc = driver.find_element_by_xpath(\"//div[@class='Wt5Tfe']\")\n",
    "#             result_asc2 = result_asc.find_elements_by_xpath(\"//div[@jsname='Cpkphb']\")\n",
    "#             result_asc1 = result_asc.find_elements_by_xpath(\"//div[@class='yuRUbf']/a\")\n",
    "#         except:\n",
    "#             print('Нeт блока asc')\n",
    "#             pass\n",
    "#     except:\n",
    "#         print('Не собрались данные')\n",
    "#         pass\n",
    "#     inindex.clear()\n",
    "#     zeroresult.clear()\n",
    "#     print(len(result_stats))\n",
    "#     if (len(result_stats) == 0):        \n",
    "#         print ('Пусто')\n",
    "#         time.sleep(1)\n",
    "#         saveerr(query, score)\n",
    "# #         zeroresult.append(query)\n",
    "# #         filename = ('zero_'+fil)\n",
    "# #         savefilevital(zeroresult)\n",
    "#         return\n",
    "\n",
    "#     else:\n",
    "#         asc_urls = []\n",
    "#         if result_asc2:\n",
    "#             try:\n",
    "#                 print('обрабатываем asc')            \n",
    "#                 f = 0\n",
    "#                 for links in result_asc1:\n",
    "#                     url_filter = links.get_attribute('href')\n",
    "#                     if 'translate' in url_filter: continue\n",
    "#                     if url_filter not in asc_urls:\n",
    "#                         f = f +1\n",
    "#                         asc_urls.append(url_filter)\n",
    "#                         print(url_filter)\n",
    "#                         if f == len(result_asc2): break\n",
    "#             except:\n",
    "#                 print('Не собрались данные asc')\n",
    "#                 pass\n",
    "#         all_urls = []\n",
    "#         for links in result_stats:\n",
    "#             url_filter = links.get_attribute('href')\n",
    "#         #     if 'translate' in url_filter or 'google' in url_filter: continue\n",
    "#             if 'translate' in url_filter: continue\n",
    "#             all_urls.append(url_filter)\n",
    "#             if url_filter in asc_urls:\n",
    "#                 all_urls.remove(url_filter)\n",
    "#                 asc_urls.remove(url_filter)\n",
    "#         for links in all_urls:\n",
    "#             inindex.append([query, links, score])\n",
    "\n",
    "def parse_result2(result_asc1, result_asc2, result_stats, query, score):\n",
    "    inindex.clear()\n",
    "    zeroresult.clear()\n",
    "    print(len(result_stats))\n",
    "    if (len(result_stats) == 0):        \n",
    "        print ('Пусто')\n",
    "        time.sleep(1)\n",
    "        saveerr(query, score)\n",
    "#         zeroresult.append(query)\n",
    "#         filename = ('zero_'+fil)\n",
    "#         savefilevital(zeroresult)\n",
    "        return\n",
    "\n",
    "    else:\n",
    "        asc_urls = []\n",
    "        f = 0\n",
    "        for links in result_asc1:\n",
    "            url_filter = links.get_attribute('href')\n",
    "            if 'translate' in url_filter: continue\n",
    "            if url_filter not in asc_urls:\n",
    "                f = f +1\n",
    "                asc_urls.append(url_filter)\n",
    "                print(url_filter)\n",
    "                if f == len(result_asc2): break\n",
    "\n",
    "        all_urls = []\n",
    "        for links in result_stats:\n",
    "            url_filter = links.get_attribute('href')\n",
    "        #     if 'translate' in url_filter or 'google' in url_filter: continue\n",
    "            if 'translate' in url_filter: continue\n",
    "            all_urls.append(url_filter)\n",
    "            if url_filter in asc_urls:\n",
    "                all_urls.remove(url_filter)\n",
    "                asc_urls.remove(url_filter)\n",
    "        print(all_urls)\n",
    "        for links in all_urls:\n",
    "            inindex.append([query, links, score])\n",
    "            \n",
    "#         for links in result_stats:\n",
    "#             peopleAlsoAsk = driver.find_elements_by_xpath(\"//div[@class='Wt5Tfe']/h3/span\")\n",
    "#             #print('Результатів:', len(inindex))\n",
    "                \n",
    "# #             if (len(inindex) > 15): break\n",
    "#             url_filter = links.get_attribute('href')\n",
    "#             if 'translate' in url_filter or 'google' in url_filter: continue\n",
    "#             print(query, url_filter)\n",
    "#             inindex.append([query, url_filter, score])\n",
    "#             inindex.append(query, score, url_filter)\n",
    "#             savesql(query, url_filter, score)\n",
    "#         filename = fil\n",
    "#         savefile(inindex)\n",
    "        savesqllist(inindex)\n",
    "        # удаляем из таблицы ключ\n",
    "        delete_keyword = f\"DELETE FROM keywords WHERE fraza = '{query}'\"\n",
    "        execute_query(connection, delete_keyword)\n",
    "            #elif (len(inindex) <= 10):\n",
    "    \n",
    "#parse_result\n",
    "def parse_result(result_stats, query, score):\n",
    "    inindex.clear()\n",
    "    zeroresult.clear()\n",
    "    print(len(result_stats))\n",
    "    if (len(result_stats) == 0):        \n",
    "        print ('Пусто')\n",
    "        time.sleep(1)\n",
    "        saveerr(query, score)\n",
    "#         zeroresult.append(query)\n",
    "#         filename = ('zero_'+fil)\n",
    "#         savefilevital(zeroresult)\n",
    "        return\n",
    "\n",
    "    else:\n",
    "        for links in result_stats:\n",
    "            #print('Результатів:', len(inindex))\n",
    "                \n",
    "#             if (len(inindex) > 15): break\n",
    "            url_filter = links.get_attribute('href')\n",
    "            if 'translate' in url_filter or 'google' in url_filter: continue\n",
    "            print(query, url_filter)\n",
    "            inindex.append([query, url_filter, score])\n",
    "#             inindex.append(query, score, url_filter)\n",
    "#             savesql(query, url_filter, score)\n",
    "#         filename = fil\n",
    "#         savefile(inindex)\n",
    "        savesqllist(inindex)\n",
    "        # удаляем из таблицы ключ\n",
    "        delete_keyword = f\"DELETE FROM keywords WHERE fraza = '{query}'\"\n",
    "        execute_query(connection, delete_keyword)\n",
    "            #elif (len(inindex) <= 10):\n",
    "\n",
    "#get_chromedriver Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36\n",
    "def get_chromedriver(use_proxy=False, user_agent=None):\n",
    "    global PROXY_HOST\n",
    "    global proxies\n",
    "#     useragent_random = useragent_r()\n",
    "#     print(useragent_random)\n",
    "    useragent_random = useragent\n",
    "    path = os.path.dirname(os.path.abspath(r\"C:\\Users\\Lids1.SERVER\\Desktop\\Python\\selenium\\chrome1\\chromedriver\"))\n",
    "#     path = os.path.dirname(os.path.abspath(r\"C:\\Users\\Admin\\Documents\\Python\\selenium\\chrome\\chromedriver\"))\n",
    "#     path = os.path.dirname(os.path.abspath(r\"C:\\Users\\Lids1\\Desktop\\SEO\\Python\\selenium\\chrome\\chromedriver\"))\n",
    "    if len(proxies) < 3:\n",
    "        proxies = listOfproxy(fileproxy)\n",
    "#         proxies = list(map(lambda x: x, pro.keys()))\n",
    "    PROXY_HOST = secrets.choice(proxies)\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.headless = True\n",
    "    # disable webdriver mode\n",
    "\n",
    "    # for ChromeDriver version 79.0.3945.16 or over\n",
    "    chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "#     chrome_options.add_argument(f'user-agent={useragent}')\n",
    "    #chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    #chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    chrome_options.add_argument(f\"user-agent={useragent_random}\")\n",
    "    \n",
    "    \n",
    "    proxy_options = {\n",
    "        'proxy': {\n",
    "            'https': f'https://{PROXY_USER}:{PROXY_PASS}@{PROXY_HOST}:{PROXY_PORT}'\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    driver = webdriver.Chrome(\n",
    "        os.path.join(path, 'chromedriver'),\n",
    "        seleniumwire_options=proxy_options,\n",
    "        options=chrome_options)\n",
    "#     print (PROXY_HOST)\n",
    "    return driver\n",
    "\n",
    "def get_driver(query, score):\n",
    "    \n",
    "    driver = get_chromedriver(use_proxy=True)\n",
    "    try:\n",
    "        queryl = re.sub('\\s','%20',query)\n",
    "        takeurl = f'https://www.google.{zone}/search?q={queryl}&pws=0&uule={uule}&hl={hl}&gl={country}&ip=0.0.0.0&source_ip=0.0.0.0&num={num}'\n",
    "#         takeurl = f'https://www.google.com.ua/webhp?hl={hl}&uule={uule}&gl={country}&ip=0.0.0.0&source_ip=0.0.0.0&num={num}'\n",
    "        driver.get(takeurl)\n",
    "        time.sleep(1)\n",
    "#         search_box = driver.find_element_by_name('q')\n",
    "#         search_box.send_keys(query)\n",
    "#         search_box.submit()\n",
    "        time.sleep(1)\n",
    "        # Проверяем если капча\n",
    "        result_search = driver.find_elements_by_xpath(\"//form[@id='captcha-form']\")\n",
    "        if (result_search):\n",
    "            print ('Reboot proxy')\n",
    "            proxies.remove(PROXY_HOST)\n",
    "            time.sleep(1)\n",
    "            driver.close()\n",
    "            driver.quit()\n",
    "            try: os.system(\"taskkill /im chromedriver.exe\")\n",
    "            except: pass\n",
    "            get_driver(query, score)\n",
    "        else:\n",
    "            # Проверяем если нет результатов в выдаче\n",
    "            try:\n",
    "                result_num = driver.find_elements_by_xpath(\"//div[@id='result-stats']\")[0]\n",
    "                if result_num.text.split(' ')[2] == '0': return\n",
    "            except:pass\n",
    "            try:\n",
    "                result_num = driver.find_element_by_xpath(\"//div[@class='card-section']\")\n",
    "                if len(result_num.text.split(' ')[:2]) == 2: return\n",
    "            except:pass\n",
    "            print('parsing')\n",
    "            try:\n",
    "                result_stats = driver.find_elements_by_xpath(\"//div[@class='yuRUbf']/a\")\n",
    "                result_asc = driver.find_element_by_xpath(\"//div[@class='Wt5Tfe']\")\n",
    "                result_asc2 = result_asc.find_elements_by_xpath(\"//div[@jsname='Cpkphb']\")\n",
    "                result_asc1 = result_asc.find_elements_by_xpath(\"//div[@class='yuRUbf']/a\")\n",
    "            except:\n",
    "                print('ошибка сбора данных')\n",
    "                pass\n",
    "#             result_stats = driver.find_elements_by_xpath(\"//div[@class='r']/a\")\n",
    "            print('Обработка')\n",
    "#             parse_result(driver, query, score)\n",
    "            parse_result(result_asc1, result_asc2, result_stats, query, score)\n",
    "            time.sleep(1)\n",
    "#             # удаляем из таблицы ключ\n",
    "#             delete_keyword = f\"DELETE FROM keywords WHERE fraza = '{query}'\"\n",
    "#             execute_query(connection, delete_keyword)\n",
    "            driver.close()\n",
    "            driver.quit()\n",
    "#             try: os.system(\"taskkill /im chromedriver.exe\")\n",
    "#             except: pass\n",
    "            return\n",
    "    except:\n",
    "        driver.close()\n",
    "        driver.quit()\n",
    "        time.sleep(10)\n",
    "        print('Перезапуск get_driver(query, score)')\n",
    "#         try: os.system(\"taskkill /im chromedriver.exe\")\n",
    "#         except: pass\n",
    "        get_driver(query, score)\n",
    "        pass\n",
    "def read_queries_list_from_file(filename):\n",
    "    f = open( filename, mode = 'r', encoding = 'utf-8' )    \n",
    "    return [x.strip() for x in f]\n",
    "\n",
    "\n",
    "# keywords_value = {}\n",
    "# def getkeys(file):\n",
    "#     i = 0\n",
    "#     with open(file, encoding=\"utf8\") as csvfile:\n",
    "#         spamreader = csv.reader(csvfile, delimiter=\";\")\n",
    "#         next(spamreader)\n",
    "#         for row in spamreader:\n",
    "#             i += 1\n",
    "#             print('Done -', i)\n",
    "#             query = row[1].strip().replace('\\ufeff', '')\n",
    "#             score = row[2]\n",
    "#             get_driver(query, score)\n",
    "\n",
    "\n",
    "def getkeys(keywords):\n",
    "    delete_grup = \"DELETE FROM errkeys\"\n",
    "    execute_query(connection, delete_grup)\n",
    "    i = 0\n",
    "    for row in keywords:\n",
    "        clear_output(wait=True)\n",
    "        i += 1\n",
    "        print('Done -', i)\n",
    "        query = row[1]\n",
    "        score = row[2]\n",
    "        print(query, score)\n",
    "        get_driver(query, score)\n",
    "        \n",
    "        \n",
    "def main():\n",
    "    # получаем прокси\n",
    "    proxies = listOfproxy(fileproxy)\n",
    "\n",
    "    select_keywords = \"SELECT * from keywords\"\n",
    "    keywords = execute_read_query(connection, select_keywords)\n",
    "    getkeys(keywords)\n",
    "    # пороверка на ошибки сбора\n",
    "    select_keywords = \"SELECT * from errkeys\"\n",
    "    keywords = execute_read_query(connection, select_keywords)\n",
    "    if keywords:\n",
    "        print(\"Досбор\")\n",
    "        getkeys(keywords)\n",
    "    select_keywords = \"SELECT * from errkeys\"\n",
    "    keywords = execute_read_query(connection, select_keywords)\n",
    "\n",
    "    print('Не собрано', len(keywords), 'Done')\n",
    "\n",
    "    # os.startfile(fil)        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Кластеризатор из базы данных + value Soft+ \n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def execute_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "        \n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        connection.commit()\n",
    "#         print(\"Query executed successfully\")\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "        \n",
    "def execute_read_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    result = None\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        result = cursor.fetchall()\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "        \n",
    "delete_grup = \"DELETE FROM grup\"\n",
    "execute_query(connection, delete_grup)\n",
    "\n",
    "clasterKeys = []\n",
    "clasterKey = []\n",
    "\n",
    "\n",
    "select_keywords = \"SELECT * from keywords2\"\n",
    "keywords = execute_read_query(connection, select_keywords)\n",
    "\n",
    "top_urls = \"SELECT * from top\"\n",
    "top_urls = execute_read_query(connection, top_urls)\n",
    "\n",
    "for i in tqdm(keywords):\n",
    "#     clear_output(wait=True)\n",
    "    keyword = i[1]\n",
    "    if keyword in clasterKeys: continue\n",
    "\n",
    "#     clasterKeyM = []\n",
    "#     clasterKeyM = list(map(lambda x: x[2], list(filter(lambda x: x[1] == keyword, top_urls))))\n",
    "    clasterKeys.append(keyword)\n",
    "\n",
    "\n",
    "    for h in keywords:\n",
    "        lastkeyword = clasterKeys[-1]\n",
    "        clasterKeyM = []\n",
    "        clasterKeyM = list(map(lambda x: x[2], list(filter(lambda x: x[1] == lastkeyword, top_urls))))\n",
    "#         clear_output(wait=True)\n",
    "        keynext = h[1]\n",
    "        value = h[2]\n",
    "        if keynext in clasterKeys: continue\n",
    "\n",
    "        clasterKeyD = []\n",
    "        clasterKeyD = list(map(lambda x: x[2], list(filter(lambda x: x[1] == keynext, top_urls))))\n",
    "\n",
    "        result=list(set(clasterKeyM) & set(clasterKeyD)) \n",
    "\n",
    "        if len(result) > 2:\n",
    "\n",
    "            clasterKeys.append(keynext)\n",
    "\n",
    "\n",
    "            create_groop = f\"\"\"\n",
    "            INSERT INTO\n",
    "              `grup` (`grope`, `keyw`, `score`)\n",
    "            VALUES\n",
    "              ('{keyword}', '{keynext}', '{value}');\n",
    "            \"\"\"\n",
    "\n",
    "            execute_query(connection, create_groop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Кластеризатор из базы данных + value Soft Dont work\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def execute_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "        \n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        connection.commit()\n",
    "#         print(\"Query executed successfully\")\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "        \n",
    "def execute_read_query(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    result = None\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        result = cursor.fetchall()\n",
    "        return result\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "        \n",
    "delete_grup = \"DELETE FROM grup\"\n",
    "execute_query(connection, delete_grup)\n",
    "\n",
    "clasterKeys = []\n",
    "clasterKey = []\n",
    "typeCl = 'Soft'\n",
    "\n",
    "select_keywords = \"SELECT * from keywords2\"\n",
    "keywords = execute_read_query(connection, select_keywords)\n",
    "\n",
    "top_urls = \"SELECT * from top\"\n",
    "top_urls = execute_read_query(connection, top_urls)\n",
    "\n",
    "for i in tqdm(keywords):\n",
    "#     clear_output(wait=True)\n",
    "    keyword = i[1]\n",
    "    if keyword in clasterKeys: continue\n",
    "\n",
    "#     clasterKeyM = []\n",
    "#     clasterKeyM = list(map(lambda x: x[2], list(filter(lambda x: x[1] == keyword, top_urls))))\n",
    "    clasterKeys.append(keyword)\n",
    "\n",
    "\n",
    "    for h in keywords:\n",
    "        lastkeyword = clasterKeys[-1]\n",
    "        clasterKeyM = []\n",
    "        clasterKeyM = list(map(lambda x: x[2], list(filter(lambda x: x[1] == lastkeyword, top_urls))))\n",
    "#         clear_output(wait=True)\n",
    "        keynext = h[1]\n",
    "        value = h[2]\n",
    "        if keynext in clasterKeys: continue\n",
    "\n",
    "        clasterKeyD = []\n",
    "        clasterKeyD = list(map(lambda x: x[2], list(filter(lambda x: x[1] == keynext, top_urls))))\n",
    "\n",
    "        result=list(set(clasterKeyM) & set(clasterKeyD)) \n",
    "\n",
    "        if len(result) > 2:\n",
    "\n",
    "            clasterKeys.append(keynext)\n",
    "\n",
    "\n",
    "            create_groop = f\"\"\"\n",
    "            INSERT INTO\n",
    "              `grup` (`grope`, `keyw`, `score`)\n",
    "            VALUES\n",
    "              ('{keyword}', '{keynext}', '{value}');\n",
    "            \"\"\"\n",
    "\n",
    "            execute_query(connection, create_groop)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
